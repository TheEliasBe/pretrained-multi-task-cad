# Core
torch==2.4.0
lightning>=2.0.0
transformers>=4.36.0
bitsandbytes>=0.41.1
deepspeed>=0.10.0
dgl>=1.1.2
peft>=0.5.0
wandb
ruamel.yaml
psutil
huggingface
omegaconf
seaborn
plotly
trimesh
torch-geometric
StrEnum
cadquery
cairosvg
# tree-sitter-python

# Code evaluation
codebleu

# UI and formatting
rich

# Profiling & logging
memory-profiler
line-profiler

# Optional for logging
mlflow
tensorboard

# If running on CUDA
nvidia-pyindex; platform_system=="Linux"
nvidia-cublas-cu11; platform_system=="Linux"

# Inference Server
python-multipart